{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occasional-memorabilia",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Idea \n",
    "The proposed project will focus on utilizing deep learning to detect facial expressions in humans. While there have been many projects in the past that dealt with expression classification: (https://github.com/atulapra/Emotion-detection) and (https://tinyurl.com/1m4km78w), one motif we noticed throughout examining these projects is that the training accuracy on the expression classifier is often much higher than the validation accuracy. In other words, it may be the case that these models have a hard time generalizing expressions among different faces. This is perhaps due to the large variety of different faces present in the dataset.\n",
    "\n",
    "While we will not attempt to improve the ability of deep learning models to generalize facial expression in this project, we will attempt to improve model performance for specific users. The overall idea is to train a model jointly, using both a general dataset of facial expressions as well as a dataset of a particular user’s facial expressions.\n",
    "\n",
    "## Pipeline Overview\n",
    "There will be three main parts to the pipline we want to create. Facial detection, general expression classification, and specific expression classification. Images containing (or not) human faces will be fed into the pipeline. Now, the first step in the pipeline will be to detect faces (or lack thereof). The most convenient way to do this is to use a pre-trained model provided by OpenCV. The facial detection step of the pipeline will output cropped images of faces, which is then fed into the next (and final) step of the pipeline to perform expression classification. Now, to train the expression classification step of the pipeline, we will first train a general CNN (same architecture as here: https://github.com/atulapra/Emotion-detection) with a general facial expression dataset (FER-13). Next, we will perform transfer learning on a specific CNN. We will freeze the convolutional layers of the previously trained general CNN and use that as the convolutional layers of the specific CNN. The fully-connected layers of the original CNN will then be trained by passing a specific dataset of user’s facial expressions.\n",
    "\n",
    "## Dataset\n",
    "The general dataset we are using is FER-13 with 7 classes (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set contains 28,709 examples. The public test set contains 3,589 examples, and the private test set contains another 3,589 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "similar-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pipeline\n",
    "from src.pipeline import Pipeline\n",
    "import numpy as np\n",
    "p = Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-plumbing",
   "metadata": {},
   "source": [
    "# Pipeline Rundown\n",
    "First train the general model using the FER13 face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-stone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "detailed-motorcycle",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "We have seen in the above above pipeline that as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-terrorism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 loss: 3.7199110984802246, accuracy: 0.28125\n",
      "Batch 1 loss: 2.462484836578369, accuracy: 0.390625\n",
      "Batch 2 loss: 2.0985498428344727, accuracy: 0.4166666567325592\n",
      "Batch 3 loss: 1.6135952472686768, accuracy: 0.4140625\n",
      "Batch 4 loss: 1.9892526865005493, accuracy: 0.4124999940395355\n",
      "Batch 5 loss: 1.317931056022644, accuracy: 0.4479166567325592\n",
      "Batch 6 loss: 0.6944978833198547, accuracy: 0.4866071343421936\n",
      "Batch 7 loss: 0.9961307048797607, accuracy: 0.5\n",
      "Batch 8 loss: 1.6082189083099365, accuracy: 0.5\n",
      "Batch 9 loss: 0.7161165475845337, accuracy: 0.5218750238418579\n",
      "Batch 10 loss: 0.7754356265068054, accuracy: 0.5340909361839294\n",
      "Batch 11 loss: 0.6446535587310791, accuracy: 0.5598958134651184\n",
      "Batch 12 loss: 0.6667004823684692, accuracy: 0.5769230723381042\n",
      "Batch 13 loss: 0.5909567475318909, accuracy: 0.59375\n",
      "Batch 14 loss: 0.6396773457527161, accuracy: 0.606249988079071\n",
      "Batch 15 loss: 0.7798316478729248, accuracy: 0.61328125\n",
      "Batch 16 loss: 0.710347056388855, accuracy: 0.6176470518112183\n",
      "Batch 17 loss: 0.5281474590301514, accuracy: 0.6284722089767456\n",
      "Batch 18 loss: 0.42594993114471436, accuracy: 0.6381579041481018\n",
      "Batch 19 loss: 0.7743571996688843, accuracy: 0.6421874761581421\n",
      "Batch 20 loss: 0.4946426749229431, accuracy: 0.6502976417541504\n",
      "Batch 21 loss: 0.5875580310821533, accuracy: 0.6590909361839294\n",
      "Batch 22 loss: 0.2734324038028717, accuracy: 0.6698369383811951\n",
      "Batch 23 loss: 0.3561888337135315, accuracy: 0.6770833134651184\n",
      "Batch 24 loss: 0.4656428396701813, accuracy: 0.6850000023841858\n",
      "Batch 25 loss: 0.15104913711547852, accuracy: 0.6971153616905212\n",
      "Batch 26 loss: 0.3131304681301117, accuracy: 0.7048611044883728\n",
      "Batch 27 loss: 0.18405812978744507, accuracy: 0.7131696343421936\n",
      "Batch 28 loss: 0.176287442445755, accuracy: 0.7196969985961914\n",
      "Training epoch: 1, train accuracy: 71.96969604492188, train loss: 0.9225770974981373, valid accuracy: 96.55172729492188, valid loss: 0.16731364466249943 \n",
      "Specific training complete!\n",
      "test loss: 0.13842591917257557, test accuracy: 96.55172729492188\n",
      "Confusion matrix:\n",
      "[[20  0  0  0  0  0  0]\n",
      " [ 0 15  0  0  2  0  0]\n",
      " [ 0  0 19  0  1  0  0]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0 18  0  0]\n",
      " [ 0  0  1  0  0 11  0]\n",
      " [ 0  0  0  0  0  0 20]]\n",
      "F1-score: [1.         0.9375     0.95       1.         0.92307692 0.95652174\n",
      " 1.        ]\n",
      "test loss: 1.735067595696121, test accuracy: 55.89300537109375\n",
      "Confusion matrix:\n",
      "[[287  13  18  22  75  39  13]\n",
      " [ 28  14   1   1   8   3   1]\n",
      " [ 96   6  80  35 138 125  16]\n",
      " [ 46   1   6 767  21  43  11]\n",
      " [116   5  46  54 354  57  21]\n",
      " [ 20   0   9  18   7 361   0]\n",
      " [ 89  11  47  93 185  39 143]]\n",
      "F1-score: [0.49956484 0.26415094 0.22759602 0.8137931  0.49132547 0.66728281\n",
      " 0.35221675]\n",
      "Batch 0 loss: 4.284388542175293, accuracy: 0.3125\n",
      "Batch 1 loss: 2.796747922897339, accuracy: 0.390625\n",
      "Batch 2 loss: 2.7552173137664795, accuracy: 0.3854166567325592\n",
      "Batch 3 loss: 1.867494821548462, accuracy: 0.34375\n",
      "Batch 4 loss: 1.527142882347107, accuracy: 0.36250001192092896\n",
      "Batch 5 loss: 1.839190125465393, accuracy: 0.3854166567325592\n",
      "Batch 6 loss: 1.2460649013519287, accuracy: 0.4017857015132904\n",
      "Batch 7 loss: 1.076851725578308, accuracy: 0.4375\n",
      "Batch 8 loss: 1.036855697631836, accuracy: 0.4479166567325592\n",
      "Batch 9 loss: 0.9456510543823242, accuracy: 0.46562498807907104\n",
      "Batch 10 loss: 1.0735833644866943, accuracy: 0.4801136255264282\n",
      "Batch 11 loss: 0.822306215763092, accuracy: 0.4895833432674408\n",
      "Batch 12 loss: 0.7204359769821167, accuracy: 0.5120192170143127\n",
      "Batch 13 loss: 0.8318526148796082, accuracy: 0.5245535969734192\n",
      "Batch 14 loss: 0.7674136161804199, accuracy: 0.5395833253860474\n",
      "Batch 15 loss: 0.7340769171714783, accuracy: 0.5546875\n",
      "Batch 16 loss: 0.583779513835907, accuracy: 0.5698529481887817\n",
      "Batch 17 loss: 0.8737785220146179, accuracy: 0.5850694179534912\n",
      "Batch 18 loss: 0.6286617517471313, accuracy: 0.5970394611358643\n",
      "Batch 19 loss: 0.5003339648246765, accuracy: 0.609375\n",
      "Batch 20 loss: 0.4327430725097656, accuracy: 0.6205357313156128\n",
      "Batch 21 loss: 0.4683850407600403, accuracy: 0.6306818127632141\n",
      "Batch 22 loss: 0.4574897587299347, accuracy: 0.63722825050354\n",
      "Batch 23 loss: 0.41201528906822205, accuracy: 0.6458333134651184\n",
      "Batch 24 loss: 0.39469853043556213, accuracy: 0.6575000286102295\n",
      "Batch 25 loss: 0.37861311435699463, accuracy: 0.6658653616905212\n",
      "Batch 26 loss: 0.27080392837524414, accuracy: 0.6770833134651184\n",
      "Batch 27 loss: 0.12750183045864105, accuracy: 0.6886160969734192\n",
      "Batch 28 loss: 0.13418784737586975, accuracy: 0.6969696879386902\n",
      "Training epoch: 1, train accuracy: 69.69696807861328, train loss: 1.034078133003465, valid accuracy: 93.10344696044922, valid loss: 0.20618216320872307 \n",
      "Specific training complete!\n",
      "test loss: 0.2594075208945814, test accuracy: 91.37931060791016\n",
      "Confusion matrix:\n",
      "[[20  0  0  0  0  0  0]\n",
      " [ 0 15  0  0  2  0  0]\n",
      " [ 0  0 13  0  1  0  6]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0 18  0  0]\n",
      " [ 0  0  0  0  0 11  1]\n",
      " [ 0  0  0  0  0  0 20]]\n",
      "F1-score: [1.         0.9375     0.78787879 1.         0.92307692 0.95652174\n",
      " 0.85106383]\n",
      "test loss: 1.61928245458426, test accuracy: 58.40066909790039\n",
      "Confusion matrix:\n",
      "[[290   4  12  26  79  29  27]\n",
      " [ 35   6   1   2   8   3   1]\n",
      " [107   1  80  32 135 114  27]\n",
      " [ 38   1   3 785  19  27  22]\n",
      " [109   0  31  58 354  48  53]\n",
      " [ 22   0   7  19   7 358   2]\n",
      " [ 73   2  29  95 161  24 223]]\n",
      "F1-score: [0.50832603 0.17142857 0.24279211 0.82112971 0.5        0.70333988\n",
      " 0.46361746]\n",
      "Batch 0 loss: 2.9269700050354004, accuracy: 0.3125\n",
      "Batch 1 loss: 1.61978280544281, accuracy: 0.359375\n",
      "Batch 2 loss: 2.967459201812744, accuracy: 0.3541666567325592\n",
      "Batch 3 loss: 2.213864326477051, accuracy: 0.375\n",
      "Batch 4 loss: 1.9937251806259155, accuracy: 0.4000000059604645\n",
      "Batch 5 loss: 0.8792705535888672, accuracy: 0.453125\n",
      "Batch 6 loss: 1.2030853033065796, accuracy: 0.4821428656578064\n",
      "Batch 7 loss: 1.507330060005188, accuracy: 0.4921875\n",
      "Batch 8 loss: 0.7934722304344177, accuracy: 0.5173611044883728\n",
      "Batch 9 loss: 0.8829711675643921, accuracy: 0.528124988079071\n",
      "Batch 10 loss: 1.0994693040847778, accuracy: 0.53125\n",
      "Batch 11 loss: 1.125582218170166, accuracy: 0.5390625\n",
      "Batch 12 loss: 0.7316211462020874, accuracy: 0.5504807829856873\n",
      "Batch 13 loss: 0.9771812558174133, accuracy: 0.5647321343421936\n",
      "Batch 14 loss: 0.7546027898788452, accuracy: 0.5687500238418579\n",
      "Batch 15 loss: 0.544681966304779, accuracy: 0.58203125\n",
      "Batch 16 loss: 0.42556723952293396, accuracy: 0.595588207244873\n",
      "Batch 17 loss: 0.6251569390296936, accuracy: 0.6059027910232544\n",
      "Batch 18 loss: 0.8136127591133118, accuracy: 0.6101973652839661\n",
      "Batch 19 loss: 0.3868178725242615, accuracy: 0.620312511920929\n",
      "Batch 20 loss: 0.3069708049297333, accuracy: 0.6339285969734192\n",
      "Batch 21 loss: 0.5030653476715088, accuracy: 0.6434659361839294\n",
      "Batch 22 loss: 0.3836040496826172, accuracy: 0.65625\n",
      "Batch 23 loss: 0.43298643827438354, accuracy: 0.6666666865348816\n",
      "Batch 24 loss: 0.3559592366218567, accuracy: 0.6737499833106995\n",
      "Batch 25 loss: 0.3725188076496124, accuracy: 0.682692289352417\n",
      "Batch 26 loss: 0.2597491443157196, accuracy: 0.6921296119689941\n",
      "Batch 27 loss: 0.26694419980049133, accuracy: 0.7008928656578064\n",
      "Batch 28 loss: 0.3165930211544037, accuracy: 0.7056276798248291\n",
      "Training epoch: 1, train accuracy: 70.5627670288086, train loss: 0.9541591508635159, valid accuracy: 96.55172729492188, valid loss: 0.19873565807938576 \n",
      "Batch 0 loss: 0.21338270604610443, accuracy: 0.90625\n",
      "Batch 1 loss: 0.2857646942138672, accuracy: 0.90625\n",
      "Batch 2 loss: 0.1644294261932373, accuracy: 0.9270833134651184\n",
      "Batch 3 loss: 0.1971067488193512, accuracy: 0.9296875\n",
      "Batch 4 loss: 0.22930710017681122, accuracy: 0.918749988079071\n",
      "Batch 5 loss: 0.268674373626709, accuracy: 0.9166666865348816\n",
      "Batch 6 loss: 0.34936752915382385, accuracy: 0.9196428656578064\n",
      "Batch 7 loss: 0.15033558011054993, accuracy: 0.9296875\n",
      "Batch 8 loss: 0.14238564670085907, accuracy: 0.9340277910232544\n",
      "Batch 9 loss: 0.1093902736902237, accuracy: 0.940625011920929\n",
      "Batch 10 loss: 0.1899999976158142, accuracy: 0.9431818127632141\n",
      "Batch 11 loss: 0.12212088704109192, accuracy: 0.9479166865348816\n",
      "Batch 12 loss: 0.3810460567474365, accuracy: 0.9471153616905212\n",
      "Batch 13 loss: 0.17686773836612701, accuracy: 0.9486607313156128\n",
      "Batch 14 loss: 0.15427547693252563, accuracy: 0.9520833492279053\n",
      "Batch 15 loss: 0.16345560550689697, accuracy: 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 loss: 0.10886525362730026, accuracy: 0.9558823704719543\n",
      "Batch 17 loss: 0.1476728767156601, accuracy: 0.9565972089767456\n",
      "Batch 18 loss: 0.13531431555747986, accuracy: 0.9588815569877625\n",
      "Batch 19 loss: 0.18398337066173553, accuracy: 0.9593750238418579\n",
      "Batch 20 loss: 0.10253209620714188, accuracy: 0.9598214030265808\n",
      "Batch 21 loss: 0.159727543592453, accuracy: 0.9602272510528564\n",
      "Batch 22 loss: 0.11256750673055649, accuracy: 0.960597813129425\n",
      "Batch 23 loss: 0.25030386447906494, accuracy: 0.9583333134651184\n",
      "Batch 24 loss: 0.31999024748802185, accuracy: 0.9574999809265137\n",
      "Batch 25 loss: 0.17789095640182495, accuracy: 0.9567307829856873\n",
      "Batch 26 loss: 0.10401014238595963, accuracy: 0.9571759104728699\n",
      "Batch 27 loss: 0.21536724269390106, accuracy: 0.9564732313156128\n",
      "Batch 28 loss: 0.04337241128087044, accuracy: 0.9577922224998474\n",
      "Training epoch: 2, train accuracy: 95.77922058105469, train loss: 0.18481060926770343, valid accuracy: 98.27586364746094, valid loss: 0.049233740428462625 \n",
      "Specific training complete!\n",
      "test loss: 0.05247531688993847, test accuracy: 97.4137954711914\n",
      "Confusion matrix:\n",
      "[[20  0  0  0  0  0  0]\n",
      " [ 0 15  0  0  2  0  0]\n",
      " [ 0  0 20  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0 18  0  0]\n",
      " [ 0  0  1  0  0 11  0]\n",
      " [ 0  0  0  0  0  0 20]]\n",
      "F1-score: [1.         0.9375     0.97560976 1.         0.94736842 0.95652174\n",
      " 1.        ]\n",
      "test loss: 2.186863791003902, test accuracy: 53.46893310546875\n",
      "Confusion matrix:\n",
      "[[309   6  15  23  52  42  20]\n",
      " [ 39   5   1   1   4   5   1]\n",
      " [127   4  67  34 102 137  25]\n",
      " [ 60   0   6 757  11  50  11]\n",
      " [177   0  46  62 256  74  38]\n",
      " [ 21   0   5  17   4 367   1]\n",
      " [125   3  43  96 128  54 158]]\n",
      "F1-score: [0.46641509 0.13513514 0.19734904 0.80318302 0.4231405  0.64160839\n",
      " 0.3670151 ]\n",
      "Batch 0 loss: 2.598891019821167, accuracy: 0.4375\n",
      "Batch 1 loss: 3.4825563430786133, accuracy: 0.421875\n",
      "Batch 2 loss: 3.5429277420043945, accuracy: 0.3958333432674408\n",
      "Batch 3 loss: 2.223588228225708, accuracy: 0.40625\n",
      "Batch 4 loss: 1.8571679592132568, accuracy: 0.41874998807907104\n",
      "Batch 5 loss: 1.3404091596603394, accuracy: 0.4166666567325592\n",
      "Batch 6 loss: 0.7856303453445435, accuracy: 0.4642857015132904\n",
      "Batch 7 loss: 0.9351286292076111, accuracy: 0.48046875\n",
      "Batch 8 loss: 1.2027701139450073, accuracy: 0.5034722089767456\n",
      "Batch 9 loss: 0.8769602179527283, accuracy: 0.5249999761581421\n",
      "Batch 10 loss: 0.8786320686340332, accuracy: 0.5340909361839294\n",
      "Batch 11 loss: 0.698122501373291, accuracy: 0.5572916865348816\n",
      "Batch 12 loss: 0.7863821387290955, accuracy: 0.5625\n",
      "Batch 13 loss: 0.773733377456665, accuracy: 0.5758928656578064\n",
      "Batch 14 loss: 1.003362774848938, accuracy: 0.5791666507720947\n",
      "Batch 15 loss: 0.7471216320991516, accuracy: 0.58984375\n",
      "Batch 16 loss: 0.6247990131378174, accuracy: 0.5974264740943909\n",
      "Batch 17 loss: 0.42569589614868164, accuracy: 0.6128472089767456\n",
      "Batch 18 loss: 0.4082759618759155, accuracy: 0.625\n",
      "Batch 19 loss: 0.5329596400260925, accuracy: 0.6312500238418579\n",
      "Batch 20 loss: 0.4444275498390198, accuracy: 0.6428571343421936\n",
      "Batch 21 loss: 0.3501644730567932, accuracy: 0.65625\n",
      "Batch 22 loss: 0.373831182718277, accuracy: 0.66847825050354\n",
      "Batch 23 loss: 0.4846651554107666, accuracy: 0.6731770634651184\n",
      "Batch 24 loss: 0.32573413848876953, accuracy: 0.6837499737739563\n",
      "Batch 25 loss: 0.21134263277053833, accuracy: 0.6959134340286255\n",
      "Batch 26 loss: 0.2783847451210022, accuracy: 0.7048611044883728\n",
      "Batch 27 loss: 0.2848142087459564, accuracy: 0.7098214030265808\n",
      "Batch 28 loss: 0.38745614886283875, accuracy: 0.7164502143859863\n",
      "Training epoch: 1, train accuracy: 71.64501953125, train loss: 0.9953770688895521, valid accuracy: 97.4137954711914, valid loss: 0.13720031455159187 \n",
      "Batch 0 loss: 0.28655821084976196, accuracy: 0.9375\n",
      "Batch 1 loss: 0.27021658420562744, accuracy: 0.921875\n",
      "Batch 2 loss: 0.27504241466522217, accuracy: 0.9270833134651184\n",
      "Batch 3 loss: 0.21464714407920837, accuracy: 0.9296875\n",
      "Batch 4 loss: 0.3203788995742798, accuracy: 0.925000011920929\n",
      "Batch 5 loss: 0.1665506511926651, accuracy: 0.9322916865348816\n",
      "Batch 6 loss: 0.23301132023334503, accuracy: 0.9241071343421936\n",
      "Batch 7 loss: 0.17815865576267242, accuracy: 0.92578125\n",
      "Batch 8 loss: 0.14128850400447845, accuracy: 0.9270833134651184\n",
      "Batch 9 loss: 0.22906167805194855, accuracy: 0.9281250238418579\n",
      "Batch 10 loss: 0.21723254024982452, accuracy: 0.9261363744735718\n",
      "Batch 11 loss: 0.07524003088474274, accuracy: 0.9322916865348816\n",
      "Batch 12 loss: 0.07993458956480026, accuracy: 0.9375\n",
      "Batch 13 loss: 0.0963314101099968, accuracy: 0.9397321343421936\n",
      "Batch 14 loss: 0.23568153381347656, accuracy: 0.9416666626930237\n",
      "Batch 15 loss: 0.10097300261259079, accuracy: 0.9453125\n",
      "Batch 16 loss: 0.163042813539505, accuracy: 0.9466911554336548\n",
      "Batch 17 loss: 0.30613088607788086, accuracy: 0.9444444179534912\n",
      "Batch 18 loss: 0.05231746658682823, accuracy: 0.9473684430122375\n",
      "Batch 19 loss: 0.15552565455436707, accuracy: 0.948437511920929\n",
      "Batch 20 loss: 0.12953972816467285, accuracy: 0.949404776096344\n",
      "Batch 21 loss: 0.35792359709739685, accuracy: 0.9474431872367859\n",
      "Batch 22 loss: 0.048008546233177185, accuracy: 0.94972825050354\n",
      "Batch 23 loss: 0.11120609194040298, accuracy: 0.9505208134651184\n",
      "Batch 24 loss: 0.12251755595207214, accuracy: 0.9524999856948853\n",
      "Batch 25 loss: 0.15289349853992462, accuracy: 0.9519230723381042\n",
      "Batch 26 loss: 0.08626209199428558, accuracy: 0.9537037014961243\n",
      "Batch 27 loss: 0.28241151571273804, accuracy: 0.953125\n",
      "Batch 28 loss: 0.22638759016990662, accuracy: 0.9534631967544556\n",
      "Training epoch: 2, train accuracy: 95.34632110595703, train loss: 0.18325773125578618, valid accuracy: 99.13793182373047, valid loss: 0.03400216402951628 \n",
      "Batch 0 loss: 0.04588954895734787, accuracy: 0.96875\n",
      "Batch 1 loss: 0.11923922598361969, accuracy: 0.96875\n",
      "Batch 2 loss: 0.09032982587814331, accuracy: 0.96875\n",
      "Batch 3 loss: 0.14214099943637848, accuracy: 0.9609375\n",
      "Batch 4 loss: 0.06528065353631973, accuracy: 0.96875\n",
      "Batch 5 loss: 0.0988021120429039, accuracy: 0.96875\n",
      "Batch 6 loss: 0.018115773797035217, accuracy: 0.9732142686843872\n",
      "Batch 7 loss: 0.07879146188497543, accuracy: 0.97265625\n",
      "Batch 8 loss: 0.16823837161064148, accuracy: 0.9722222089767456\n",
      "Batch 9 loss: 0.1446915566921234, accuracy: 0.96875\n",
      "Batch 10 loss: 0.42193546891212463, accuracy: 0.9630681872367859\n",
      "Batch 11 loss: 0.06633564829826355, accuracy: 0.9661458134651184\n",
      "Batch 12 loss: 0.01605275832116604, accuracy: 0.96875\n",
      "Batch 13 loss: 0.08277218043804169, accuracy: 0.96875\n",
      "Batch 14 loss: 0.028355395421385765, accuracy: 0.9708333611488342\n",
      "Batch 15 loss: 0.05174408480525017, accuracy: 0.97265625\n",
      "Batch 16 loss: 0.21968738734722137, accuracy: 0.970588207244873\n",
      "Batch 17 loss: 0.13764464855194092, accuracy: 0.9704861044883728\n",
      "Batch 18 loss: 0.20394721627235413, accuracy: 0.9703947305679321\n",
      "Batch 19 loss: 0.04620428383350372, accuracy: 0.971875011920929\n",
      "Batch 20 loss: 0.12777067720890045, accuracy: 0.9702380895614624\n",
      "Batch 21 loss: 0.09253601729869843, accuracy: 0.9701704382896423\n",
      "Batch 22 loss: 0.18150512874126434, accuracy: 0.96875\n",
      "Batch 23 loss: 0.06125447526574135, accuracy: 0.96875\n",
      "Batch 24 loss: 0.5125026106834412, accuracy: 0.96875\n",
      "Batch 25 loss: 0.022294864058494568, accuracy: 0.9699519276618958\n",
      "Batch 26 loss: 0.01877131126821041, accuracy: 0.9710648059844971\n",
      "Batch 27 loss: 0.011029273271560669, accuracy: 0.9720982313156128\n",
      "Batch 28 loss: 0.10690521448850632, accuracy: 0.9707792401313782\n",
      "Training epoch: 3, train accuracy: 97.07791900634766, train loss: 0.11657821290708821, valid accuracy: 99.13793182373047, valid loss: 0.015980804106220603 \n",
      "Specific training complete!\n",
      "test loss: 0.007981920696871984, test accuracy: 100.0\n",
      "Confusion matrix:\n",
      "[[20  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0 18  0  0]\n",
      " [ 0  0  0  0  0 12  0]\n",
      " [ 0  0  0  0  0  0 20]]\n",
      "F1-score: [1. 1. 1. 1. 1. 1. 1.]\n",
      "test loss: 2.80534518852339, test accuracy: 50.09751892089844\n",
      "Confusion matrix:\n",
      "[[304   7  13  25  36  71  11]\n",
      " [ 43   4   1   2   2   4   0]\n",
      " [149   3  60  34  78 161  11]\n",
      " [ 62   0   4 744  11  67   7]\n",
      " [222   6  46  64 190 102  23]\n",
      " [ 16   1   9  16   2 371   0]\n",
      " [153   3  49  97 109  71 125]]\n",
      "F1-score: [0.42937853 0.1        0.17699115 0.7927544  0.35152636 0.58795563\n",
      " 0.31887755]\n",
      "Batch 0 loss: 3.6069061756134033, accuracy: 0.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loss: 2.10217547416687, accuracy: 0.265625\n",
      "Batch 2 loss: 3.0598769187927246, accuracy: 0.28125\n",
      "Batch 3 loss: 1.9270883798599243, accuracy: 0.3203125\n",
      "Batch 4 loss: 2.019350528717041, accuracy: 0.3499999940395355\n",
      "Batch 5 loss: 1.3169177770614624, accuracy: 0.4010416567325592\n",
      "Batch 6 loss: 1.4602123498916626, accuracy: 0.4196428656578064\n",
      "Batch 7 loss: 1.0853402614593506, accuracy: 0.44140625\n",
      "Batch 8 loss: 1.0032358169555664, accuracy: 0.46875\n",
      "Batch 9 loss: 0.8948014378547668, accuracy: 0.4937500059604645\n",
      "Batch 10 loss: 0.8104081153869629, accuracy: 0.5113636255264282\n",
      "Batch 11 loss: 0.7394240498542786, accuracy: 0.5260416865348816\n",
      "Batch 12 loss: 0.9059305191040039, accuracy: 0.536057710647583\n",
      "Batch 13 loss: 0.6744673848152161, accuracy: 0.5535714030265808\n",
      "Batch 14 loss: 0.46789148449897766, accuracy: 0.5729166865348816\n",
      "Batch 15 loss: 0.5698440074920654, accuracy: 0.587890625\n",
      "Batch 16 loss: 0.39233294129371643, accuracy: 0.6066176295280457\n",
      "Batch 17 loss: 0.6833062171936035, accuracy: 0.6180555820465088\n",
      "Batch 18 loss: 0.518316388130188, accuracy: 0.6332237124443054\n",
      "Batch 19 loss: 0.4267879128456116, accuracy: 0.6468750238418579\n",
      "Batch 20 loss: 0.6190857887268066, accuracy: 0.65625\n",
      "Batch 21 loss: 0.5259408950805664, accuracy: 0.6619318127632141\n",
      "Batch 22 loss: 0.36087319254875183, accuracy: 0.6711956262588501\n",
      "Batch 23 loss: 0.33976083993911743, accuracy: 0.68359375\n",
      "Batch 24 loss: 0.33163657784461975, accuracy: 0.6924999952316284\n",
      "Batch 25 loss: 0.3471522331237793, accuracy: 0.7007211446762085\n",
      "Batch 26 loss: 0.23828476667404175, accuracy: 0.7106481194496155\n",
      "Batch 27 loss: 0.27919819951057434, accuracy: 0.7198660969734192\n",
      "Batch 28 loss: 0.24119479954242706, accuracy: 0.7251082062721252\n",
      "Training epoch: 1, train accuracy: 72.51082611083984, train loss: 0.9637152218613131, valid accuracy: 97.4137954711914, valid loss: 0.1949965227395296 \n",
      "Batch 0 loss: 0.3303772211074829, accuracy: 0.875\n",
      "Batch 1 loss: 0.600199282169342, accuracy: 0.890625\n",
      "Batch 2 loss: 0.1458369493484497, accuracy: 0.9270833134651184\n",
      "Batch 3 loss: 0.314157098531723, accuracy: 0.9296875\n",
      "Batch 4 loss: 0.16329260170459747, accuracy: 0.9375\n",
      "Batch 5 loss: 0.19288024306297302, accuracy: 0.9375\n",
      "Batch 6 loss: 0.16975703835487366, accuracy: 0.9375\n",
      "Batch 7 loss: 0.24978165328502655, accuracy: 0.93359375\n",
      "Batch 8 loss: 0.11984797567129135, accuracy: 0.9340277910232544\n",
      "Batch 9 loss: 0.06589467078447342, accuracy: 0.940625011920929\n",
      "Batch 10 loss: 0.20860174298286438, accuracy: 0.9431818127632141\n",
      "Batch 11 loss: 0.2277585119009018, accuracy: 0.9401041865348816\n",
      "Batch 12 loss: 0.13213132321834564, accuracy: 0.942307710647583\n",
      "Batch 13 loss: 0.12416030466556549, accuracy: 0.9441964030265808\n",
      "Batch 14 loss: 0.13273507356643677, accuracy: 0.9458333253860474\n",
      "Batch 15 loss: 0.13304013013839722, accuracy: 0.9453125\n",
      "Batch 16 loss: 0.25027716159820557, accuracy: 0.9448529481887817\n",
      "Batch 17 loss: 0.09595710784196854, accuracy: 0.9461805820465088\n",
      "Batch 18 loss: 0.19463002681732178, accuracy: 0.9457237124443054\n",
      "Batch 19 loss: 0.23412024974822998, accuracy: 0.942187488079071\n",
      "Batch 20 loss: 0.2786850929260254, accuracy: 0.9389880895614624\n",
      "Batch 21 loss: 0.045258741825819016, accuracy: 0.9417613744735718\n",
      "Batch 22 loss: 0.04656246304512024, accuracy: 0.9442934989929199\n",
      "Batch 23 loss: 0.14424818754196167, accuracy: 0.9440104365348816\n",
      "Batch 24 loss: 0.1325974464416504, accuracy: 0.9437500238418579\n",
      "Batch 25 loss: 0.0498523972928524, accuracy: 0.9459134340286255\n",
      "Batch 26 loss: 0.08418889343738556, accuracy: 0.9467592835426331\n",
      "Batch 27 loss: 0.18606193363666534, accuracy: 0.9475446343421936\n",
      "Batch 28 loss: 0.059934813529253006, accuracy: 0.948051929473877\n",
      "Training epoch: 2, train accuracy: 94.80519104003906, train loss: 0.1763043564198346, valid accuracy: 98.27586364746094, valid loss: 0.04851246043108404 \n",
      "Batch 0 loss: 0.0723830908536911, accuracy: 0.96875\n",
      "Batch 1 loss: 0.11865651607513428, accuracy: 0.953125\n",
      "Batch 2 loss: 0.12910667061805725, accuracy: 0.9479166865348816\n",
      "Batch 3 loss: 0.04315735399723053, accuracy: 0.953125\n",
      "Batch 4 loss: 0.05118483677506447, accuracy: 0.9624999761581421\n",
      "Batch 5 loss: 0.041439201682806015, accuracy: 0.96875\n",
      "Batch 6 loss: 0.037589479237794876, accuracy: 0.9732142686843872\n",
      "Batch 7 loss: 0.18329274654388428, accuracy: 0.97265625\n",
      "Batch 8 loss: 0.09251221269369125, accuracy: 0.9722222089767456\n",
      "Batch 9 loss: 0.07628599554300308, accuracy: 0.9750000238418579\n",
      "Batch 10 loss: 0.037421565502882004, accuracy: 0.9772727489471436\n",
      "Batch 11 loss: 0.09976648539304733, accuracy: 0.9765625\n",
      "Batch 12 loss: 0.1226549968123436, accuracy: 0.9759615659713745\n",
      "Batch 13 loss: 0.4625663459300995, accuracy: 0.9709821343421936\n",
      "Batch 14 loss: 0.1634533703327179, accuracy: 0.9708333611488342\n",
      "Batch 15 loss: 0.030502207577228546, accuracy: 0.97265625\n",
      "Batch 16 loss: 0.04552311450242996, accuracy: 0.9742646813392639\n",
      "Batch 17 loss: 0.16590575873851776, accuracy: 0.9722222089767456\n",
      "Batch 18 loss: 0.13362759351730347, accuracy: 0.9720394611358643\n",
      "Batch 19 loss: 0.06806328892707825, accuracy: 0.971875011920929\n",
      "Batch 20 loss: 0.08406215906143188, accuracy: 0.9717261791229248\n",
      "Batch 21 loss: 0.03609359636902809, accuracy: 0.9730113744735718\n",
      "Batch 22 loss: 0.04568353295326233, accuracy: 0.9741848111152649\n",
      "Batch 23 loss: 0.10942894220352173, accuracy: 0.9739583134651184\n",
      "Batch 24 loss: 0.04454454034566879, accuracy: 0.9737499952316284\n",
      "Batch 25 loss: 0.1034293845295906, accuracy: 0.973557710647583\n",
      "Batch 26 loss: 0.0764554962515831, accuracy: 0.9733796119689941\n",
      "Batch 27 loss: 0.037186041474342346, accuracy: 0.9743303656578064\n",
      "Batch 28 loss: 0.047770384699106216, accuracy: 0.9751082062721252\n",
      "Training epoch: 3, train accuracy: 97.51082611083984, train loss: 0.09516368652212209, valid accuracy: 100.0, valid loss: 0.009003062616102397 \n",
      "Batch 0 loss: 0.01522759534418583, accuracy: 1.0\n",
      "Batch 1 loss: 0.019525012001395226, accuracy: 1.0\n",
      "Batch 2 loss: 0.04628525301814079, accuracy: 0.9895833134651184\n",
      "Batch 3 loss: 0.023882858455181122, accuracy: 0.9921875\n",
      "Batch 4 loss: 0.03272291645407677, accuracy: 0.9937499761581421\n",
      "Batch 5 loss: 0.013185148127377033, accuracy: 0.9947916865348816\n",
      "Batch 6 loss: 0.18882107734680176, accuracy: 0.9910714030265808\n",
      "Batch 7 loss: 0.043985385447740555, accuracy: 0.9921875\n",
      "Batch 8 loss: 0.022173084318637848, accuracy: 0.9930555820465088\n",
      "Batch 9 loss: 0.05474449694156647, accuracy: 0.9906250238418579\n",
      "Batch 10 loss: 0.015078038908541203, accuracy: 0.9914772510528564\n",
      "Batch 11 loss: 0.031085850670933723, accuracy: 0.9921875\n",
      "Batch 12 loss: 0.04832041263580322, accuracy: 0.9927884340286255\n",
      "Batch 13 loss: 0.004764811135828495, accuracy: 0.9933035969734192\n",
      "Batch 14 loss: 0.3993270695209503, accuracy: 0.987500011920929\n",
      "Batch 15 loss: 0.050381265580654144, accuracy: 0.986328125\n",
      "Batch 16 loss: 0.1338496208190918, accuracy: 0.9852941036224365\n",
      "Batch 17 loss: 0.04729592800140381, accuracy: 0.9861111044883728\n",
      "Batch 18 loss: 0.08484320342540741, accuracy: 0.9851973652839661\n",
      "Batch 19 loss: 0.012067994102835655, accuracy: 0.9859374761581421\n",
      "Batch 20 loss: 0.031154431402683258, accuracy: 0.9851190447807312\n",
      "Batch 21 loss: 0.07476449012756348, accuracy: 0.9829545617103577\n",
      "Batch 22 loss: 0.04447486251592636, accuracy: 0.9823369383811951\n",
      "Batch 23 loss: 0.02559838630259037, accuracy: 0.9830729365348816\n",
      "Batch 24 loss: 0.019704312086105347, accuracy: 0.9837499856948853\n",
      "Batch 25 loss: 0.020905522629618645, accuracy: 0.984375\n",
      "Batch 26 loss: 0.047560617327690125, accuracy: 0.9837962985038757\n",
      "Batch 27 loss: 0.027657700702548027, accuracy: 0.984375\n",
      "Batch 28 loss: 0.04761117696762085, accuracy: 0.9837662577629089\n",
      "Training epoch: 4, train accuracy: 98.37662506103516, train loss: 0.05610339732134137, valid accuracy: 100.0, valid loss: 0.007431470032315701 \n",
      "Specific training complete!\n",
      "test loss: 0.004052428422201591, test accuracy: 100.0\n",
      "Confusion matrix:\n",
      "[[20  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0 18  0  0]\n",
      " [ 0  0  0  0  0 12  0]\n",
      " [ 0  0  0  0  0  0 20]]\n",
      "F1-score: [1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "pex1 = Pipeline()\n",
    "pex1.ingest_fer13_data(\"data/icml_face_data.csv\")\n",
    "pex1.ingest_specific_data(\"data/specific_dataset\", train_ratio=0.8)\n",
    "\n",
    "specific_losses = []\n",
    "specific_accuracies = []\n",
    "fer13_losses = []\n",
    "fer13_accuracies = []\n",
    "\n",
    "epochs_list = np.arange(11)\n",
    "\n",
    "\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # load the previous model\n",
    "    pex1.load_model(\"data/general_model.pt\", mode=\"train\")\n",
    "    \n",
    "    pex1.train_specific_model(\"data/temp.pt\", \n",
    "                           learning_rate=1e-3, \n",
    "                           n_epochs=epochs, \n",
    "                           stop_thr=1e-5, \n",
    "                           use_valid=True, \n",
    "                           batch_size=32)\n",
    "    \n",
    "    sp_loss, sp_acc, _, _ = pex1.evaluate_specific_model()\n",
    "    fer_loss, fer_acc, _, _ = pex1.evaluate_general_model()\n",
    "    \n",
    "    specific_accuracies.append(sp_acc)\n",
    "    specific_losses.append(sp_loss)\n",
    "    fer13_accuracies.append(fer_acc)\n",
    "    fer13_losses.append(fer_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-watson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
